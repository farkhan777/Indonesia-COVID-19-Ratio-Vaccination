# -*- coding: utf-8 -*-
"""COVID-19 Ratio Vaccination.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/164BPVoU7dwkAz4T9C-pnsYeGPSt1cLLr
"""

!pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d sinakaraji/covid-vaccination-vs-death

import os
import zipfile
# Import all required libraries
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib
import matplotlib.ticker as ticker
import matplotlib.pyplot as plt

# Importing layers from keras. Use LSTM for input layer, and Dense for hidden and output layer
from keras.layers import Dense, LSTM, Dropout, Bidirectional 
from keras.models import Sequential

# Import SGD Optimizers
from tensorflow.keras.optimizers import SGD

# Import for splitting test and training data set
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import seaborn as sns

local_zip = '/content/covid-vaccination-vs-death.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

df = pd.read_csv('/content/covid-vaccination-vs-death_ratio.csv')

df

#define values
indonesia = ["Indonesia"]

#drop rows that contain any value in the list
df = df[df.country.isin(indonesia) == True]
df

#Convert Data Types
df['date'] = pd.to_datetime(df['date'])

df.info()

# Print banyaknya vaksinasi di seluruh area Jawa Timur dari waktu ke waktu 
data_graph = df.groupby(['date', 'country'])['ratio'].max().reset_index()
data_graph.sort_values(by="date")

data_graph['date'] = pd.to_datetime(data_graph['date'])
data_graph

sorted_data_graph = data_graph.sort_values(by ='date',ascending=True)

plt.figure(figsize=(20,10))
sns.lineplot(x="date", y="ratio", data=sorted_data_graph, hue='country')
plt.title('Persebaran rasio vaksinasi dengan jumlah penduduk negara Indonesia tahun 2021',fontsize=15);

minMAE = (sorted_data_graph['ratio'].max() - sorted_data_graph['ratio'].min()) * (10/100)
minMAE

#Variables for training
cols = list(sorted_data_graph)[2:7]

df_cols = sorted_data_graph[cols].astype(float)

#LSTM used sigmoid and tanh that are sensitive to magnitude so values need to be normalized
#normalize the dataset
scaler = StandardScaler()
scaler = scaler.fit(df_cols)
df_cols_scaled = scaler.transform(df_cols)

dates = sorted_data_graph['date'].values
ratio = sorted_data_graph['ratio'].values

dates = np.asarray(dates).astype('float32')
ratio = np.asarray(ratio).astype('float32')

#As required for LSTM networks, require to reshape an input data into n_samples x timesteps
#In this example, the n_features is 2. I will make timesteps = 3
#With this, the resultant n_samples is 5 (as the input data has 9 rows)
trainX = []
trainY = []

n_future = 1 #Number of days I want to predict into the future
n_past = 14 # Number of past days I want to use to predict the future


for i in range(n_past, len(df_cols_scaled) - n_future+1):
  trainX.append(df_cols_scaled[i - n_past:i, 0:df_cols.shape[1]])
  trainY.append(df_cols_scaled[i + n_future - 1:i + n_future,0])

trainX, trainY = np.array(trainX), np.array(trainY)

print('trainX shape == {}.'.format(trainX.shape)) #holding 14 days that are looking back and 5 variables that we got
print('trainY shape == {}.'.format(trainY.shape)) # 1 is the day after n_past

model = tf.keras.models.Sequential([
                                     tf.keras.layers.LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True),
                                     tf.keras.layers.LSTM(32, activation='relu', return_sequences=False),
                                     tf.keras.layers.Dropout(0.2),
                                     tf.keras.layers.Dense(32, activation="relu"),
                                     tf.keras.layers.Dense(trainY.shape[1])    
                                   ])
 
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)

model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
  
model.summary()

#Membuat fungsi callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<0.1):
      print("\nmae kurang dari 10%")
      self.model.stop_training = True
callbacks = myCallback()

#Training Model
history = model.fit(trainX, trainY, batch_size=16, validation_split=0.2, epochs=400, verbose=2, callbacks=[callbacks])

#Plot mae
plt.plot(history.history['mae'], label='Training mae')
plt.plot(history.history['val_mae'], label='Validation mae')
plt.legend()

#Plot loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()

y_predict= model.predict(trainX)
y_predict2= model.predict(trainY)

import matplotlib.pyplot as plt
plt.plot(sorted_data_graph['ratio'].values, sorted_data_graph['date'].values)
plt.title('ACTUAL PM2.5')
plt.show()

plt.plot(range(0, len(trainX)), trainY, color='blue',
         label='actual')
plt.plot(range(0, len(trainX[:])), y_predict, color='red',
         label='prediction-train')

plt.plot(range(len(trainX),len(sorted_data_graph['ratio'].values)), trainY, color='blue')
plt.plot(range(len(trainX),len(sorted_data_graph['ratio'].values[:-10])), y_predict2, color='green',
         label='prediction-test')
plt.show()